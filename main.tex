\documentclass[journal,article,submit,moreauthors,pdftex,10pt,a4paper]{mdpi}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{float}

\usepackage[english]{babel}

\usepackage[nomain, acronym, symbols]{glossaries}

\loadglsentries{acronyms}

\definecolor{cadmiumgreen}{rgb}{0.0, 0.42, 0.24}
\definecolor{burntorange}{rgb}{0.8, 0.33, 0.0}

\newcommand{\ct}[1]{{\color{black}#1}}
\newcommand{\odo}[1]{{\color{black}#1}}
\newcommand{\gus}[1]{{\color{black}#1}}
\newcommand{\cris}[1]{{\color{black}#1}}

\firstpage{1}
\makeatletter
\setcounter{page}{\@firstpage}

\makeatother

\Title{Machine Learning Guided Adaptive Scheduling for Multi-core Real-time Operating Systems}

\begin{document}

\section{Introduction}

\gls{rtos} are systems developed to handle the processing of tasks with timing constraints, where it is necessary to
ensure that the deadlines for the tasks are met. These systems can be classified as hard or soft based on their
capabilities and requirements. Hard \gls{rtos} are used in situations where the failure to meet a deadline in the
execution of a task can have severe consequences, this includes industrial systems, autonomous vehicles, avionic
systems and others. Alternatively, soft \gls{rtos} are used in non-critical contexts, where deadline misses can be
tolerated to a certain degree. Multimedia and audio processing are examples of contexts where a soft \gls{rtos} might
be used \cite[13--22]{kopetz2022real}.

The deterministic execution of tasks is ensured by real-time scheduling algorithms, which are responsible for their
prioritization. These algorithms must order the tasks in such a way that their timing constraints are satisfied, for
that, the execution time, deadlines and other aspects of tasks can be considered. Schedulers that set the priorities
before the execution of the system are classified as static, while those that set the priorities at runtime are
classified as dynamic \cite[247--248]{kopetz2022real}.

Currently, several processor architectures are multi-core, allowing real parallelism in task execution. These
architectures introduce challenges in the implementation of real-time schedulers, as the use of shared resources, such
as the memory, cache and input/output can affect the execution time of tasks in non-deterministic ways
\cite{aceituno2023optimized, lugo2022survey}. Moreover, there also problems related to the efficient usage of the
cores, such as load balancing \cite{jadon2024comprehensive}. Overall, the complexity of real-time task scheduling in
multi-core \gls{rtos} can require more sophisticated schedulers.

% TODO: Justify this better
Considering this scenario, different scheduling techniques have been proposed over the last years. Some of them apply
heuristics, such as genetic algorithms, to optimize the system's performance. There is also the utilization of
\gls{ml}, mainly with \gls{rl} \cite{hassan2025optimizing, liang2024adaptive}. The utilization of \gls{ml} is useful
for capturing patterns and learn how to adapt the scheduling to the state of the system. However, this technique can
introduce a significant overhead, which is a often overlooked impact.

% Inference?
% TODO: Check the genitives
This study proposes the development of an adaptive dynamic scheduler for multi-core \gls{rtos} that will be guided by a
\gls{ml} model, focusing on the improvement of the system's performance while keeping a low overhead. The
prioritization policy of the tasks will be based on the inference realized by the \gls{ml} model over the temporal
evolution of the system's state. This will allow the tasks to be scheduled with the consideration of factors that
affect the timing.

\section{Research Problem}

\section{Objectives}

O objetivo principal deste trabalho é investigar e desenvolver um algoritmo de escalonamento informado por \gls{ml}
para \gls{rtos} \textit{multicore}, buscando aprimorar o desempenho do sistema e contribuir para o estado da arte da
aplicação de \gls{ml} em \gls{rtos}.

\subsection{Specific Objectives}

\begin{itemize}
    \item Realizar uma revisão sistemática sobre a aplicação de \gls{ml} em \gls{rtos};
    \item Desenvolver um modelo de \gls{ml} para a inferência do estado do sistema;
    \item Desenvolver o algoritmo de escalonamento, utilizando o modelo treinado para informar o algoritmo;
    \item Validar a solução proposta, avaliando seu desempenho e \textit{overhead} sob diversos cenários de teste;
    \item Analisar os resultados obtidos, comparando a solução com o estado da arte.
\end{itemize}

\section{Estado da Arte}

No cenário de escalonamento para \gls{rtos} \textit{multicore}, diversas propostas buscam solucionar problemas
pertinentes, muitas delas focando em sistemas críticos em ambientes embarcados \cite{ismael2021scheduling}. Um dos
desafios relevantes é a mitigação da interferência entre tarefas, originada pelo compartilhamento de recursos. Embora
soluções de escalonamento tenham sido propostas para resolver esse problema, elas ainda encontram-se limitadas
\cite{lugo2022survey}. Além disso, a distribuição eficiente da carga de trabalho entre os núcleos também é um problema
investigado. Contudo, muitas das soluções propostas para o balanceamento de carga ainda são limitadas por problemas
como a heterogeneidade das arquiteturas, escalabilidade, dinamicidade das cargas de trabalho e \textit{overheads}
inerentes à complexidade dos escalonadores \cite{jadon2024comprehensive}.

Com a utilização de sistemas de tempo real em ambientes embarcados com fontes limitadas de energia, a eficiência
energética se tornou um tópico relevante na área. Nesse contexto, são utilizados em algoritmos técnicas que envolvem
\gls{dvfs} e também heurísticas para minimizar o consumo de energia \cite{chniter2020improved, antolak2021energy}.

A aplicação de \gls{ml} no contexto de escalonamento \textit{multicore} foca em vários objetivos, como, por exemplo, na
otimização do escalonamento através de \gls{rl} e também na aplicação de \gls{drl} para a otimização do escalonamento
em arquiteturas heterogêneas \cite{liang2024adaptive, tan2024deep}. A eficiência energética também é um dos focos,
sendo que vários trabalhos propostos nessa linha utilizam \gls{ml}, aplicando \gls{drl}, redes de \gls{lstm}, regressão
linear e \glspl{cnn} \cite{peng2024energy, allaqband2024efficient, khan2025enhanced}. De modo geral, essas soluções
aplicam \gls{ml} para modelar o comportamento do sistema e das aplicações, analisando dados como contadores de
desempenho, características das tarefas e suas dependências. A partir disso, são tomadas as decisões relacionadas ao
escalonamento ou outros aspectos.

Além do escalonamento, \gls{ml} também é utilizado em contextos mais gerais de otimização e gerenciamento de eficiência
energética e temperatura \cite{pagani2018machine}. Por fim, há estudos que demonstram a viabilidade da aplicação de
\gls{ml} em \gls{rtos} de forma não intrusiva e eficiente \cite{hoffmann2021online, horstmann2019framework}. Em geral,
ainda há espaço para avançar com soluções que utilizam modelos mais explicáveis e generalistas quanto a arquiteturas
\textit{multicore}.

\section{Contribuições}

Considerando o estado da arte, esse trabalho contribuirá com o desenvolvimento de um escalonador adaptativo guiado
por um modelo de \gls{ml} que possa operar eficientemente sob cenários mais complexos com cargas de trabalho variadas.
Graças a técnicas de implementação e coleta de dados não disruptivas, é esperado que essa solução tenha um
\textit{overhead} baixo \cite{horstmann2019framework, passig2023monitoring}. Adicionalmente, o trabalho oferecerá uma
revisão aprofundada do estado da arte de algoritmos de escalonamento guiados por \gls{ml}.

\section{Metodologia}

O projeto se trata de uma pesquisa aplicada e será iniciado com uma pesquisa exploratória, visando o desenvolvimento da
fundamentação teórica e o estabelecimento do estado da arte. A implementação prática se baseará nos fundamentos do
\textit{framework} de \citet{horstmann2019framework} e utilizará o \gls{rtos} \gls{epos} \cite{epos}. Inicialmente,
será feito um estudo sobre as métricas e dados relevantes a serem incluídos no treinamento do modelo. Posteriormente,
uma estratégia de treinamento e arquitetura serão definidas, seguidas por uma validação preliminar do modelo antes do
avanço para a próxima etapa. Em sequência, o escalonador será implementado com a integração do modelo treinado para
a captura do estado do sistema. Por fim, a solução será testada experimentalmente e os resultados serão analisados e
documentados.

\newpage

\bibliography{references}

\end{document}
